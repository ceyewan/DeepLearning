{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-03-09T10:47:10.774097Z","iopub.status.busy":"2022-03-09T10:47:10.773780Z","iopub.status.idle":"2022-03-09T10:47:10.779843Z","shell.execute_reply":"2022-03-09T10:47:10.779001Z","shell.execute_reply.started":"2022-03-09T10:47:10.774067Z"},"trusted":true},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mUnable to start Kernel 'pytorch (Python 3.9.7)' due to connection timeout. \n","View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["\"\"\"\n","Import necessary libraries to create a generative adversarial network\n","The code is mainly developed using the PyTorch library\n","\"\"\"\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import transforms\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import PIL\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T10:47:10.781659Z","iopub.status.busy":"2022-03-09T10:47:10.781425Z","iopub.status.idle":"2022-03-09T10:47:10.800392Z","shell.execute_reply":"2022-03-09T10:47:10.799611Z","shell.execute_reply.started":"2022-03-09T10:47:10.781631Z"},"trusted":true},"outputs":[],"source":["\"\"\"\n","Determine if any GPUs are available\n","\"\"\"\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T10:47:10.805793Z","iopub.status.busy":"2022-03-09T10:47:10.805350Z","iopub.status.idle":"2022-03-09T10:47:18.652248Z","shell.execute_reply":"2022-03-09T10:47:18.651389Z","shell.execute_reply.started":"2022-03-09T10:47:10.805718Z"},"trusted":true},"outputs":[],"source":["#Setting image parameters for the surface crack database\n","imsize=227 # 227x227 images\n","in_chan = 3 # RGB\n","out_chan = 2 # 2 output classes: positive and negative\n","\n","#Setting Hyperparameters\n","epochs = 100\n","learning_rate = 1e-3\n","decay = 1e-8\n","batch_size = 64 \n","kernel_size = 5\n","#adding transforms to the image \n","transform = transforms.Compose([\n","    #cropping the centre\n","    transforms.CenterCrop(imsize),\n","    #adding random rotations\n","    transforms.RandomRotation([0,360],resample=PIL.Image.BILINEAR),\n","    #transforming the dataset to Torch tensors\n","    transforms.ToTensor(),\n","    #normalising the image\n","    transforms.Normalize((0.0229,), (0.0957,))])\n","#loading the dataset and applying the transforms\n","dataset = datasets.ImageFolder('../input/surface-crack-detection',transform=transform)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T10:47:18.655026Z","iopub.status.busy":"2022-03-09T10:47:18.654311Z","iopub.status.idle":"2022-03-09T10:47:18.680715Z","shell.execute_reply":"2022-03-09T10:47:18.679631Z","shell.execute_reply.started":"2022-03-09T10:47:18.654992Z"},"trusted":true},"outputs":[],"source":["#Loading the data into a data loader, chop them into batches and shuffle the batches everytime this object is called\n","train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","#Initialise a model \n","model = LeNet(in_chan=in_chan, out_chan=out_chan, imsize=imsize, kernel_size=kernel_size)\n","#Add Adam optimiser with a weight decay parameter to penalise big weights\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=decay)\n","\n","epoch_trainaccs, epoch_valaccs = [], []\n","epoch_trainloss, epoch_valloss = [], []\n","for epoch in range(epochs):  # loop over the dataset multiple times\n","        #set the model to train mode (gradient acquiring)\n","        model.train()\n","        train_losses,  train_accs = [], []; acc = 0\n","        #iterate through the train_loader\n","        for batch, (x_train, y_train) in enumerate(train_loader):\n","            #clear previous gradients\n","            model.zero_grad()\n","            #forward propagate the model\n","            pred = model(x_train)\n","            #Use the cross entropy loss because it's logistical regression\n","            loss = F.cross_entropy(pred,y_train)\n","            #backpropagate the loss\n","            loss.backward()\n","            #optimise the weights accordingly\n","            optimizer.step()\n","            #calculate the training accuracy\n","            acc = (pred.argmax(dim=-1) == y_train).to(torch.float32).mean()\n","            train_accs.append(acc.mean().item())\n","            train_losses.append(loss.item())   \n","            print(\"Batch=\",batch,\" loss = \",loss.item(), \" accuracy = \",acc.item())\n","            \n","        epoch_trainloss.append(np.mean(train_losses))\n","        epoch_trainaccs.append(np.mean(train_accs))\n","        print(\"Epoch = \",epoch,\" Mean loss = \",np.mean(train_losses))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:47:18.681703Z","iopub.status.idle":"2022-03-09T10:47:18.682047Z","shell.execute_reply":"2022-03-09T10:47:18.681900Z","shell.execute_reply.started":"2022-03-09T10:47:18.681878Z"},"trusted":true},"outputs":[],"source":["\"\"\"\n","Network Architectures\n","The following are the discriminator and generator architectures\n","\"\"\"\n","\n","class discriminator(nn.Module):\n","    def __init__(self):\n","        super(discriminator, self).__init__()\n","        self.fc1 = nn.Linear(784, 512)\n","        self.fc2 = nn.Linear(512, 1)\n","        self.activation = nn.LeakyReLU(0.1)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 784)\n","        x = self.activation(self.fc1(x))\n","        x = self.fc2(x)\n","        return nn.Sigmoid()(x)\n","\n","\n","class generator(nn.Module):\n","    def __init__(self):\n","        super(generator, self).__init__()\n","        self.fc1 = nn.Linear(128, 1024)\n","        self.fc2 = nn.Linear(1024, 2048)\n","        self.fc3 = nn.Linear(2048, 784)\n","        self.activation = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.activation(self.fc1(x))\n","        x = self.activation(self.fc2(x))\n","        x = self.fc3(x)\n","        x = x.view(-1, 1, 28, 28)\n","        return nn.Tanh()(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:47:18.683850Z","iopub.status.idle":"2022-03-09T10:47:18.684162Z","shell.execute_reply":"2022-03-09T10:47:18.684011Z","shell.execute_reply.started":"2022-03-09T10:47:18.683995Z"},"trusted":true},"outputs":[],"source":["\"\"\"\n","Network training procedure\n","Every step both the loss for disciminator and generator is updated\n","Discriminator aims to classify reals and fakes\n","Generator aims to generate images as realistic as possible\n","\"\"\"\n","epochs = 100\n","for epoch in range(epochs):\n","    for idx, (imgs, _) in enumerate(train_loader):\n","        idx += 1\n","\n","        # Training the discriminator\n","        # Real inputs are actual images of the MNIST dataset\n","        # Fake inputs are from the generator\n","        # Real inputs should be classified as 1 and fake as 0\n","        real_inputs = imgs.to(device)\n","        real_outputs = D(real_inputs)\n","        real_label = torch.ones(real_inputs.shape[0], 1).to(device)\n","\n","        noise = (torch.rand(real_inputs.shape[0], 128) - 0.5) / 0.5\n","        noise = noise.to(device)\n","        fake_inputs = G(noise)\n","        fake_outputs = D(fake_inputs)\n","        fake_label = torch.zeros(fake_inputs.shape[0], 1).to(device)\n","\n","        outputs = torch.cat((real_outputs, fake_outputs), 0)\n","        targets = torch.cat((real_label, fake_label), 0)\n","\n","        D_loss = loss(outputs, targets)\n","        D_optimizer.zero_grad()\n","        D_loss.backward()\n","        D_optimizer.step()\n","\n","        # Training the generator\n","        # For generator, goal is to make the discriminator believe everything is 1\n","        noise = (torch.rand(real_inputs.shape[0], 128)-0.5)/0.5\n","        noise = noise.to(device)\n","\n","        fake_inputs = G(noise)\n","        fake_outputs = D(fake_inputs)\n","        fake_targets = torch.ones([fake_inputs.shape[0], 1]).to(device)\n","        G_loss = loss(fake_outputs, fake_targets)\n","        G_optimizer.zero_grad()\n","        G_loss.backward()\n","        G_optimizer.step()\n","\n","        if idx % 100 == 0 or idx == len(train_loader):\n","            print('Epoch {} Iteration {}: discriminator_loss {:.3f} generator_loss {:.3f}'.format(epoch, idx, D_loss.item(), G_loss.item()))\n","\n","    if (epoch+1) % 10 == 0:\n","        torch.save(G, 'Generator_epoch_{}.pth'.format(epoch))\n","        print('Model saved.')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":4}
